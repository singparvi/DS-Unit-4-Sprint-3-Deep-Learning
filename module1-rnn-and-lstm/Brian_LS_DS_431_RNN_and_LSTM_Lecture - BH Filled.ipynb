{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "LS_DS_431_RNN_and_LSTM_Lecture - BH Filled.ipynb",
   "provenance": [],
   "collapsed_sections": [],
   "toc_visible": true
  },
  "kernelspec": {
   "name": "u4-s1-nlp",
   "language": "python",
   "display_name": "U4-S1-NLP (Python3)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ldr0HZ193GKb"
   },
   "source": [
    "Lambda School Data Science\n",
    "\n",
    "*Unit 4, Sprint 3, Module 1*\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Et2y0gP7IM19"
   },
   "source": [
    "# Recurrent Neural Networks (RNNs) and Long Short Term Memory (LSTM) (Prepare)\n",
    "\n",
    "![](https://wiki.tum.de/download/attachments/22578349/GATES.gif?version=1&modificationDate=1486083227237&api=v2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-BOMScPtIM1-"
   },
   "source": [
    "## Learning Objectives\n",
    "- <a href=\"#p1\">Part 1: </a>Describe Neural Networks used for modeling sequences\n",
    "- <a href=\"#p2\">Part 2: </a>Apply a LSTM to a text generation problem using Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_IizNKWLomoA"
   },
   "source": [
    "-----\n",
    "# Overview\n",
    "\n",
    "### Let's start with sequences \n",
    "\n",
    "A sequence is just any collection of numbers - order counts and repetition is allowed. \n",
    "\n",
    "Python lists are a good elemental example - `[1, 2, 2, -1]` is a valid list and is different from `[1, 2, -1, 2]`. \n",
    "\n",
    "What you might not be as familiar with are recusive numbers. For that, let's talk about a specific example, namely the **Fibonacci Sequence**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "44QZgrPUe3-Y"
   },
   "source": [
    "# Neural Networks for Sequences (Learn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dX_WLYHrIM1_"
   },
   "source": [
    "\n",
    "\n",
    "Before we dive into the inner workings of an LSTM model, let's try to understand and appreciate the recusive relationships of numbers in both pure mathematics and in the physical reality in which we find ourselves embedded. \n",
    "\n",
    "\n",
    "As usually we take attempt to understand a concept from at least 3 different perspectives:\n",
    "- Algebraic\n",
    "- Geometric\n",
    "- Coding an example\n",
    "\n",
    "\n",
    "A [**recurrence relation**](https://en.wikipedia.org/wiki/Recurrence_relation) in math is an equation that uses recursion to define a sequence of numbers - a famous example is the Fibonacci numbers.\n",
    "\n",
    "Here is the algorithm for generating the numbers in the Fibonacci sequence: \n",
    "\n",
    "$$F_n = F_{n-1} + F_{n-2}$$\n",
    "\n",
    "You need a base case $F_0=1, F_1=1$ (i.e. a starting point) to get the sequence started and then from then on our the sequence is self-generating. \n",
    "\n",
    "So this means that we can start generating our sequence: \n",
    "\n",
    "$$F_0=1,~~  F_1=1 $$\n",
    "\n",
    "$$F_2 = F_{1} + F_{0} ~=~ 1 + 1 ~=~ 2$$\n",
    "\n",
    "Then\n",
    "\n",
    "$$F_3 = F_{2} + F_{1} ~=~ 2 + 1 ~=~ 3$$\n",
    "\n",
    "Then \n",
    "\n",
    "$$F_4 = F_{3} + F_{2} ~=~ 3 + 2 ~=~ 5$$\n",
    "\n",
    "Then \n",
    "\n",
    "$$F_5 = F_{4} + F_{3} ~=~ 5 + 3 ~=~ 8$$\n",
    "\n",
    "I hope you get the idea. \n",
    "\n",
    "Before we we code up this sequence, let's appreciate how important and ubiquitous it is in nature. \n",
    "\n",
    "![](http://www.davidbeahm.com/wp-content/uploads/2011/11/fibonacci-1024x637.jpg)\n",
    "\n",
    "\n",
    "![](https://i.pinimg.com/originals/32/d7/47/32d747bea24f4756dc4c5ffe61b36efd.jpg)\n",
    "\n",
    "![](https://i.pinimg.com/originals/f2/cb/34/f2cb3452dd774bab87bbee2b8a77d4bb.png)\n",
    "\n",
    "\n",
    "![](https://f4.bcbits.com/img/a3628582449_10.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5Smaks5ZvsUz"
   },
   "source": [
    "**Take Away:** \n",
    "- Recursive sequences are located everywhere in life - but we need to know what we're looking for and where to look for it. \n",
    "- Simply try to develop an appreciation for the connection between mathematics and all of physical reality. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vSmZquFPvsU0"
   },
   "source": [
    "### Code up the Fibonacci Sequence\n",
    "Again, here is the algorithm for the Fibonacci numbers.  \n",
    "\n",
    "\n",
    "$$F_n = F_{n-1} + F_{n-2}$$\n",
    "\n",
    "\n",
    "You need a base case to get your sequence started. This time let  $F_0=0 ~\\text{and}~ F_1=1$. \n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "eG8IKUZBvsU1",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1622302481782,
     "user_tz": 300,
     "elapsed": 108,
     "user": {
      "displayName": "Brian Hu",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gg9C2hp-ML87Vme0BJw6zcKYZK-PtGb0Cpg1J1S=s64",
      "userId": "16141489273393480079"
     }
    }
   },
   "source": [
    "def fibo(n):\n",
    "    \"\"\"\n",
    "    Calculate and return the next number in the Fibonacci sequence\n",
    "    \n",
    "    Input\n",
    "    -----\n",
    "    n: int or float\n",
    "        The nth number in the sequence (think of it as an index for a list)\n",
    "        \n",
    "    Return\n",
    "    ------\n",
    "    F_n: the next number in the sequence generated from the previous two numbers in the sequence \n",
    "    \"\"\"\n",
    "    \n",
    "    if n <= 1:\n",
    "        # if n = 0, then return 0 \n",
    "        return n\n",
    "    else:\n",
    "        # this is the recursive part \n",
    "        # notice how the function is a function of itself!\n",
    "        #  F_n =       F_n-1 + F_n-2\n",
    "        return(fibo(n-1) + fibo(n-2))"
   ],
   "execution_count": 1,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d5757486eecafe9c2c1af5b428e482b3",
     "grade": false,
     "grade_id": "cell-b31ecb0aaf3ace76",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hFMQ8pFevsU3",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1622302482918,
     "user_tz": 300,
     "elapsed": 166,
     "user": {
      "displayName": "Brian Hu",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gg9C2hp-ML87Vme0BJw6zcKYZK-PtGb0Cpg1J1S=s64",
      "userId": "16141489273393480079"
     }
    },
    "outputId": "8374c30c-79ac-4b1d-9fe5-e6cb8ea2281f"
   },
   "source": [
    "# generate a Fibonacci Sequence\n",
    "# YOUR CODE HERE\n",
    "# raise NotImplementedError()\n",
    "\n",
    "fibo(8)"
   ],
   "execution_count": 2,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "21"
      ]
     },
     "metadata": {
      "tags": []
     },
     "execution_count": 2
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3hRzuEkZvsU3"
   },
   "source": [
    "**Take Away:** \n",
    "\n",
    "Recursive algorithms have as input their previous output. In order words, the output at time step `t - 1`, becomes in the input in the following time step `t`. This is the key idea of that you should observe. Because it is this recursive behavior that is new to how we will think about neural networks, specifically the LSTM model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d9q_afmlvsU4"
   },
   "source": [
    "-----\n",
    "\n",
    "## Introduction to Recursive Neural Networks (RNNs) \n",
    "\n",
    "\n",
    "The nice thing about spending time to understand the Fibonacci Sequence is that we can then `borrow the intuition` that we picked up to help us understand how the LSTM works. \n",
    "\n",
    "Different Recursive Neural Networks (RNNs) have this recursive loop in their architecture. The ML research community first created the following RNN model using the standard Fully-Connected Forward Feeding (FCFF) model: \n",
    "\n",
    "![](https://nerdthecoder.files.wordpress.com/2019/02/731df-0mrhhgabskajpbt21.png)\n",
    "\n",
    "`This type of RNN had severe limitations!` \n",
    "\n",
    "- It didn't have long-term memory capacity to learn long input sequences \n",
    "- It suffered from the [Vanishing Gradient Problem](https://en.wikipedia.org/wiki/Vanishing_gradient_problem).\n",
    "\n",
    "In response to these limitations, the ML research community created the LSTM model, which ditched the FCFF architecture and started using the following architecture:\n",
    "\n",
    "![Long short-term memory unit](https://upload.wikimedia.org/wikipedia/commons/thumb/6/63/Long_Short-Term_Memory.svg/1024px-Long_Short-Term_Memory.svg.png)\n",
    "\n",
    "Wow! Ok! There's a lot going on here, isn't there? Well, don't worry, we are going to break this model down bit-by-bit so we can understand what is happening. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J1Q_sRkQvsU6"
   },
   "source": [
    "_____\n",
    "\n",
    "\n",
    "## Theory of LSTM\n",
    "\n",
    "One of the simplist and clearest explanations of the LSTM model can be found [**here!**](https://colah.github.io/posts/2015-08-Understanding-LSTMs/) - a beautifully clear and concise explaination the model's archtecture and the mathematics. This link will serve as our main resouce for understanding how LSTMs work. \n",
    "\n",
    "Below are the equations for each of the gates that are explained in the article. \n",
    "\n",
    "Although, you will not be held responsible for the equations in any quiz, module assignment, or Sprint Challenge - it is still instructive to be exposed to them at least once.\n",
    "\n",
    "First thing to notice is that each gate equation (not the cell states) has the form of a perceptron. \n",
    "\n",
    "`Remember the perceptron?` It's the fundamental building block of neural networks - it's not going away! \n",
    "\n",
    "Once you understand that, it will hopefully become gradually clear that each gate is a perceptron with a different job to do. \n",
    "\n",
    "That's it. \n",
    "\n",
    "It's just 4 perceptrons, each with a different job to do. \n",
    "\n",
    "Fortunately, you already know about perceptrons (you built one from scratch in `Sprint 2 Module 1`). \n",
    "\n",
    "____\n",
    "\n",
    "### Gates in More Detail\n",
    "\n",
    "#### Forget Gate\n",
    "This neuron's job is to use the current input to learn what information the cell state should forget regarding long-term dependencies. \n",
    "\n",
    "\n",
    "$$f_t = \\sigma(W_f \\cdot [h_{t-1},x_t]~+~b_f)$$\n",
    "\n",
    "#### Input Gate\n",
    "This neuron's job is to use the current input to learn what new information to include in the cell state. \n",
    "\n",
    "\n",
    "$$i_t = \\sigma(W_i \\cdot [h_{t-1},x_t]~+~b_i)$$\n",
    "\n",
    "#### Candidate Cell State \n",
    "This neuron's job is to use the current input to create a candidate cell state.\n",
    "\n",
    "This new candidate cell state will be used to update the model's final cell state.\n",
    "\n",
    "$$\\tilde{C}_t = \\text{tanh}(W_C \\cdot [h_{t-1},x_t]~+~b_C)$$\n",
    "\n",
    "#### New Cell State\n",
    "This is where the candidate and old cell state are combined to create a new cell state.\n",
    "\n",
    "This is where output from the forget gate $f_t$ is used to scaled the old cell state\n",
    "\n",
    "- If $f_t$'s value is closer to 0.0, then less information from the previous cell state is retained.\n",
    "- If $f_t$'s value is closer to 1.0, then more information from the previous cell state is retained. \n",
    "\n",
    "\n",
    "This is also where the output of the input gate $i_t$ is used to scaled the candidate cell state. \n",
    "- If $i_t$'s value is closer to 0.0, then less information from the candidate cell state is retained\n",
    "- If $i_t$'s value is closer to 1.0, then more information from the candidate cell state is retained. \n",
    "\n",
    "Finally, you combine the two scaled cell states to form the new cell state of the model. \n",
    "\n",
    "It is $C_t$ that will be passed into the next training step and used by the output to make a final prediction. \n",
    "\n",
    "$$C_t = f_t*C_{t-1} + i_t*\\tilde{C}_t$$\n",
    "\n",
    "#### Output Gate\n",
    "This is where the actual output of the model is calcuated. \n",
    "\n",
    "The article denotes the model's pre-scaled output as $o_t$ and the scaled output as $h_t$. To be clear, it is $h_t$ that ultimately gets outputed as the model's final prediction. \n",
    "\n",
    "We are familiar with the notation $y$ to denote a model's prediction instead of using $h$. But they both mean the same thing - the model's final prediction. \n",
    "\n",
    "This neuron's job is to take the current input and make a prediction. \n",
    "\n",
    "$$o_t = \\sigma(W_o \\cdot [h_{t-1},x_t]~+~b_o)$$\n",
    "\n",
    "Next, the cell state is used to inform the final prediction. \n",
    "\n",
    "Recall that $o_t$ is output from a sigmoid activation function, so it's value is somewhere between 0 and 1. \n",
    "\n",
    "Which means that it is being used to scale $\\text{tanh}(C_t)$ which contains the current cell state. \n",
    "\n",
    "Recall the tanh curve and you'll see that tanh is scaling $C_t$ so that it's value lies between -1 and 1; this makes it possible to have positive and negative values for the model's output. Sigmoids don't allow for the posibility of negative values, but tanh does. \n",
    "\n",
    "$$h_t = o_t*\\text{tanh}(C_t)$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i0A6r3hrvsU8"
   },
   "source": [
    "_________\n",
    "\n",
    "### Today's Application of LSTMs\n",
    "\n",
    "So why are these cool? \n",
    "\n",
    "One particularly compelling application is actually not time series but language modeling - language is inherently ordered data (letters/words go one after another, and the order *matters*). [The Unreasonable Effectiveness of Recurrent Neural Networks](https://karpathy.github.io/2015/05/21/rnn-effectiveness/) is a famous and worth reading blog post on this topic.\n",
    "\n",
    "For our purposes, let's use TensorFlow and Keras to train RNNs with natural language. \n",
    "\n",
    "Resources:\n",
    "- https://github.com/keras-team/keras/blob/master/examples/imdb_lstm.py\n",
    "- https://keras.io/layers/recurrent/#lstm\n",
    "- http://adventuresinmachinelearning.com/keras-lstm-tutorial/\n",
    "\n",
    "Note that `tensorflow.contrib` [also has an implementation of RNN/LSTM](https://www.tensorflow.org/tutorials/sequences/recurrent)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eWrQllf8WEd-"
   },
   "source": [
    "_____________\n",
    "\n",
    "\n",
    "## Follow Along\n",
    "\n",
    "Sequences come in many shapes and forms from stock prices to text. We'll focus on text, because modeling text as a sequence is a strength of Neural Networks. Let's start with a simple classification task using a TensorFlow tutorial. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SSytcRhoIM2A"
   },
   "source": [
    "### RNN/LSTM Sentiment Classification with Keras"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "Ti23G0gRe3kr",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1622302655480,
     "user_tz": 300,
     "elapsed": 1553,
     "user": {
      "displayName": "Brian Hu",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gg9C2hp-ML87Vme0BJw6zcKYZK-PtGb0Cpg1J1S=s64",
      "userId": "16141489273393480079"
     }
    }
   },
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "from tensorflow.keras.preprocessing import sequence\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Embedding, Bidirectional\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras.datasets import imdb\n",
    "import numpy as np\n",
    "import pandas as pd"
   ],
   "execution_count": 4,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "K2yUtA1gvsVA",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1622302661270,
     "user_tz": 300,
     "elapsed": 4748,
     "user": {
      "displayName": "Brian Hu",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gg9C2hp-ML87Vme0BJw6zcKYZK-PtGb0Cpg1J1S=s64",
      "userId": "16141489273393480079"
     }
    },
    "outputId": "5d6d580e-7489-4656-fd25-6960928bfb70"
   },
   "source": [
    "# load in dataset \n",
    "\n",
    "max_features = 20000\n",
    "# cut texts after this number of words (among top max_features most common words)\n",
    "maxlen = 80\n",
    "batch_size = 32\n",
    "\n",
    "print('Loading data...')\n",
    "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=max_features)\n",
    "print(len(x_train), 'train sequences')\n",
    "print(len(x_test), 'test sequences')"
   ],
   "execution_count": 5,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n",
      "17465344/17464789 [==============================] - 0s 0us/step\n"
     ],
     "name": "stdout"
    },
    {
     "output_type": "stream",
     "text": [
      "<string>:6: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/datasets/imdb.py:155: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  x_train, y_train = np.array(xs[:idx]), np.array(labels[:idx])\n"
     ],
     "name": "stderr"
    },
    {
     "output_type": "stream",
     "text": [
      "25000 train sequences\n",
      "25000 test sequences\n"
     ],
     "name": "stdout"
    },
    {
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/datasets/imdb.py:156: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  x_test, y_test = np.array(xs[idx:]), np.array(labels[idx:])\n"
     ],
     "name": "stderr"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "2XWP9TNEM8-q",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1622302661272,
     "user_tz": 300,
     "elapsed": 17,
     "user": {
      "displayName": "Brian Hu",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gg9C2hp-ML87Vme0BJw6zcKYZK-PtGb0Cpg1J1S=s64",
      "userId": "16141489273393480079"
     }
    }
   },
   "source": [
    "# documentation on this data set here: https://www.tensorflow.org/api_docs/python/tf/keras/datasets/imdb/load_data\n",
    "# the values in the lists represents the token frequncy, so \"1\" means the most frequent token in the corpus \n",
    "# each list represents a movie review"
   ],
   "execution_count": 6,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "lK9k4UKJM9EC",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1622302661274,
     "user_tz": 300,
     "elapsed": 15,
     "user": {
      "displayName": "Brian Hu",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gg9C2hp-ML87Vme0BJw6zcKYZK-PtGb0Cpg1J1S=s64",
      "userId": "16141489273393480079"
     }
    }
   },
   "source": [
    "# binary labels \n",
    "# 1 -> positive sentiment expressed in movie review\n",
    "# 0 -> negative sentiment expressed in movie review "
   ],
   "execution_count": 7,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "deletable": false,
    "id": "c0awRJCnIM2G",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "06de4d9b7986caa5aef6c537af138ee9",
     "grade": false,
     "grade_id": "cell-fb23c1d7d1168a73",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1622302738804,
     "user_tz": 300,
     "elapsed": 674,
     "user": {
      "displayName": "Brian Hu",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gg9C2hp-ML87Vme0BJw6zcKYZK-PtGb0Cpg1J1S=s64",
      "userId": "16141489273393480079"
     }
    },
    "outputId": "fb106721-cdb5-4804-a3ce-1065bd979b23"
   },
   "source": [
    "# although there are some implmentations of LSTM models that can handle variable length samples, this is not one of those models\n",
    "# so we need to standardize the length of our movies\n",
    "# reviews that are longer than maxlen are truncated\n",
    "# reivewsd that are shorter than maxlen are padded with 0 (Or some other value that you provide)\n",
    "\n",
    "# YOUR CODE HERE\n",
    "# raise NotImplementedError()\n",
    "print('Pad Sequences (samples x time)')\n",
    "x_train = sequence.pad_sequences(x_train, maxlen=maxlen) # https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/sequence/pad_sequences\n",
    "x_test = sequence.pad_sequences(x_test, maxlen=maxlen)\n",
    "print('x_train shape: ', x_train.shape)\n",
    "print('x_test shape: ', x_test.shape)\n"
   ],
   "execution_count": 9,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "Pad Sequences (samples x time)\n",
      "x_train shape:  (25000, 80)\n",
      "x_test shape:  (25000, 80)\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "39NtRAHhvsVD"
   },
   "source": [
    "### Build a 1 hidden layer LSTM language model"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "deletable": false,
    "id": "QD_NjHw-pcJS",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "200cc0a64ca234e836bf8fe83a553143",
     "grade": false,
     "grade_id": "cell-9c285c5d84213905",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1622302837535,
     "user_tz": 300,
     "elapsed": 121,
     "user": {
      "displayName": "Brian Hu",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gg9C2hp-ML87Vme0BJw6zcKYZK-PtGb0Cpg1J1S=s64",
      "userId": "16141489273393480079"
     }
    },
    "outputId": "d76d26fe-b91a-43eb-a797-930ab263a10f"
   },
   "source": [
    "# YOUR CODE HERE\n",
    "# raise NotImplementedError()\n",
    "\n",
    "from tensorflow.keras.layers import Dropout\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_features, 128))  \n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(50, activation='relu'))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(50, activation='relu'))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam', \n",
    "              metrics=['accuracy'])\n",
    "model.summary()"
   ],
   "execution_count": 12,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, None, 128)         2560000   \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, None, 128)         0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, None, 50)          6450      \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, None, 50)          0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, None, 50)          2550      \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, None, 50)          0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, None, 1)           51        \n",
      "=================================================================\n",
      "Total params: 2,569,051\n",
      "Trainable params: 2,569,051\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "W99hsV0MvsVE",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1622302862090,
     "user_tz": 300,
     "elapsed": 23642,
     "user": {
      "displayName": "Brian Hu",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gg9C2hp-ML87Vme0BJw6zcKYZK-PtGb0Cpg1J1S=s64",
      "userId": "16141489273393480079"
     }
    },
    "outputId": "b52f469c-b0d8-4e1c-850e-fe180680b846"
   },
   "source": [
    "results_one_layer = model.fit(x_train, y_train,\n",
    "                      batch_size=256, \n",
    "                      epochs=5, \n",
    "                      validation_data=(x_test,y_test))"
   ],
   "execution_count": 13,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "98/98 [==============================] - 8s 42ms/step - loss: 0.6846 - accuracy: 0.5466 - val_loss: 0.6796 - val_accuracy: 0.5519\n",
      "Epoch 2/5\n",
      "98/98 [==============================] - 4s 40ms/step - loss: 0.6751 - accuracy: 0.5632 - val_loss: 0.6792 - val_accuracy: 0.5553\n",
      "Epoch 3/5\n",
      "98/98 [==============================] - 4s 39ms/step - loss: 0.6726 - accuracy: 0.5658 - val_loss: 0.6803 - val_accuracy: 0.5556\n",
      "Epoch 4/5\n",
      "98/98 [==============================] - 4s 38ms/step - loss: 0.6715 - accuracy: 0.5663 - val_loss: 0.6805 - val_accuracy: 0.5558\n",
      "Epoch 5/5\n",
      "98/98 [==============================] - 4s 38ms/step - loss: 0.6707 - accuracy: 0.5677 - val_loss: 0.6810 - val_accuracy: 0.5557\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LTY6KZDEvsVE"
   },
   "source": [
    "### Build a 1 hidden layer Bidirectional LSTM language model\n",
    "\n",
    "A Bidirectional LSTM, or biLSTM, is a sequence processing model that consists of two LSTMs: **one taking the input in a forward direction**, and **the other in a backwards direction**. BiLSTMs effectively increase the amount of information available to the network, improving the context available to the algorithm (e.g. knowing what words immediately follow and precede a word in a sentence).\n",
    "\n",
    "![](https://miro.medium.com/max/764/1*6QnPUSv_t9BY9Fv8_aLb-Q.png)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "deletable": false,
    "id": "cKyGb4TzIM2O",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b7058ca0b8f53f28530be9c93a8bef46",
     "grade": false,
     "grade_id": "cell-706b7be103484984",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1622303053981,
     "user_tz": 300,
     "elapsed": 1918,
     "user": {
      "displayName": "Brian Hu",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gg9C2hp-ML87Vme0BJw6zcKYZK-PtGb0Cpg1J1S=s64",
      "userId": "16141489273393480079"
     }
    },
    "outputId": "a2777d54-8efa-4c1e-f37c-ed3b950f069e"
   },
   "source": [
    "# YOUR CODE HERE\n",
    "# raise NotImplementedError()\n",
    "\n",
    "from tensorflow.keras.layers import Bidirectional\n",
    "\n",
    "# increase dropout up to 0.6 does not help, , activation='relu' not really useful\n",
    "# Define LSTM Architecture\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_features, 128, input_length=maxlen))\n",
    "model.add(LSTM(128, return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "# If you want to stack LSTM layers (need to return sequences i.e. hiddent state)\n",
    "model.add(LSTM(128, return_sequences=True))\n",
    "model.add(Dropout(0.2))   \n",
    "\n",
    "# If you want to add Bidirectional LSTM\n",
    "model.add(Bidirectional(LSTM(128)))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "             optimizer='adam', \n",
    "             metrics=['accuracy'])\n",
    "model.summary()"
   ],
   "execution_count": 14,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (None, 80, 128)           2560000   \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 80, 128)           131584    \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 80, 128)           0         \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 80, 128)           131584    \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 80, 128)           0         \n",
      "_________________________________________________________________\n",
      "bidirectional (Bidirectional (None, 256)               263168    \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 3,086,593\n",
      "Trainable params: 3,086,593\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aJT3lCVsvsVF",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1622303103252,
     "user_tz": 300,
     "elapsed": 49153,
     "user": {
      "displayName": "Brian Hu",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gg9C2hp-ML87Vme0BJw6zcKYZK-PtGb0Cpg1J1S=s64",
      "userId": "16141489273393480079"
     }
    },
    "outputId": "2fe4d0d9-744d-47e3-fed3-1294bb6e66a8"
   },
   "source": [
    "results_biLSTM = model.fit(x_train, y_train,\n",
    "                      batch_size=256, \n",
    "                      epochs=5, \n",
    "                      validation_data=(x_test,y_test))"
   ],
   "execution_count": 15,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "98/98 [==============================] - 17s 93ms/step - loss: 0.4693 - accuracy: 0.7561 - val_loss: 0.3671 - val_accuracy: 0.8368\n",
      "Epoch 2/5\n",
      "98/98 [==============================] - 8s 81ms/step - loss: 0.2560 - accuracy: 0.8991 - val_loss: 0.3843 - val_accuracy: 0.8338\n",
      "Epoch 3/5\n",
      "98/98 [==============================] - 8s 81ms/step - loss: 0.1800 - accuracy: 0.9336 - val_loss: 0.4482 - val_accuracy: 0.8192\n",
      "Epoch 4/5\n",
      "98/98 [==============================] - 8s 81ms/step - loss: 0.1070 - accuracy: 0.9623 - val_loss: 0.4929 - val_accuracy: 0.8140\n",
      "Epoch 5/5\n",
      "98/98 [==============================] - 8s 81ms/step - loss: 0.0627 - accuracy: 0.9792 - val_loss: 0.6546 - val_accuracy: 0.8091\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 404
    },
    "id": "RZx3Zs7tIM2Q",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1622303103406,
     "user_tz": 300,
     "elapsed": 192,
     "user": {
      "displayName": "Brian Hu",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gg9C2hp-ML87Vme0BJw6zcKYZK-PtGb0Cpg1J1S=s64",
      "userId": "16141489273393480079"
     }
    },
    "outputId": "0ae2984a-733d-4706-f9f7-b4f58874bb4a"
   },
   "source": [
    "# Plot training & validation loss values\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "epoch_list = np.arange(1,6)\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.grid()\n",
    "plt.xticks(epoch_list)\n",
    "# results for 1-layer lstm model\n",
    "plt.plot(epoch_list, results_one_layer.history['loss'], \"--\", label=\"1 layer Train\")\n",
    "plt.plot(epoch_list, results_one_layer.history['val_loss'], \"--\", label = \"1 layer Test\")\n",
    "\n",
    "# results for 3-layer lstm model\n",
    "plt.plot(epoch_list, results_biLSTM.history['loss'], label=\"biLSTM Train \")\n",
    "plt.plot(epoch_list, results_biLSTM.history['val_loss'], label = \"biLSTM Test\")\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend()\n",
    "plt.show();"
   ],
   "execution_count": 16,
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": [],
      "needs_background": "light"
     }
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L9Ps3CauIM2S"
   },
   "source": [
    "## Challenge\n",
    "\n",
    "You will be expected to use an Keras LSTM for a classicification task on the *Sprint Challenge*. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7pETWPIe362y"
   },
   "source": [
    "--------\n",
    "# LSTM Text generation with Keras (Learn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fTv7rZOQvsVH"
   },
   "source": [
    "Using sequential models to generate text data is a very popular application of recursive deep learning models. A couple of popular applications are [**chat bots**](https://hackernoon.com/deep-learning-chatbot-everything-you-need-to-know-r11jm30bc) and language translators such as [**google translate**](https://ai.googleblog.com/2020/06/recent-advances-in-google-translate.html). \n",
    "\n",
    "In order to properly build a chat bot or translater you need to use multiple lstm models in an encoder & decoder framwork known as a [**sequence 2 sequence model**](https://keras.io/examples/nlp/lstm_seq2seq/) .\n",
    "\n",
    "\n",
    "![](https://jeddy92.github.io/images/ts_intro/seq2seq_lang.png)\n",
    "\n",
    "Also, now a days, using a standard LSTM isn't enough. You also have to use a version of lstm seq2seq models known as [**transformers**](https://towardsdatascience.com/transformers-141e32e69591). Transformers give seq2seq models the capacity to pay attention to specific portions of the input sequence, the most relevent portion in order to make a prediction. Yes, that's right, humanity has figured out how to convert attention into an algorithm. Next stop, self-awareness! \n",
    "\n",
    "The above mentions of sequence 2 sequence models and transformers are for a larger contextual understanding of the landscape of language models and how LSTMs fit into this landscape. Although **we will cover the endcoder/decoder framework in a future lesson, transformers are outside the scope of Unit 4**. However, once you learn about LSTMs and encoder/decoder frameworks, you will have all necessary information to then go on and learn about transformers on your own. At that point, the only really new bit you'll be learning is the [**attention mechanism**](https://towardsdatascience.com/intuitive-understanding-of-attention-mechanism-in-deep-learning-6c9482aecf4f). \n",
    "\n",
    "\n",
    "As a first pass at text generation, we'll stick to standard LSTM models. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BK-GrUGvIM2T"
   },
   "source": [
    "-----\n",
    "# Text Generation using LSTMs\n",
    "\n",
    "What else can we do with LSTMs? Since we're analyzing the *sequence*, we can do more than classify - we can *generate* text. I'ved pulled some news stories using [newspaper](https://github.com/codelucas/newspaper/).\n",
    "\n",
    "This example is drawn from the Keras [documentation](https://keras.io/examples/lstm_text_generation/)."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "q64qHEYIIM2U",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1622303672453,
     "user_tz": 300,
     "elapsed": 198,
     "user": {
      "displayName": "Brian Hu",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gg9C2hp-ML87Vme0BJw6zcKYZK-PtGb0Cpg1J1S=s64",
      "userId": "16141489273393480079"
     }
    }
   },
   "source": [
    "from tensorflow.keras.callbacks import LambdaCallback\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing import sequence\n",
    "\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import sys\n",
    "import os"
   ],
   "execution_count": 19,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "knk9YYBlvsVI",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1622303738369,
     "user_tz": 300,
     "elapsed": 117,
     "user": {
      "displayName": "Brian Hu",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gg9C2hp-ML87Vme0BJw6zcKYZK-PtGb0Cpg1J1S=s64",
      "userId": "16141489273393480079"
     }
    }
   },
   "source": [
    "# a custom data prep class that we'll be using \n",
    "# from data_cleaning_toolkit_class import data_cleaning_toolkit"
   ],
   "execution_count": 21,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "id": "MxcXsdsSIM2W",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1622303739730,
     "user_tz": 300,
     "elapsed": 276,
     "user": {
      "displayName": "Brian Hu",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gg9C2hp-ML87Vme0BJw6zcKYZK-PtGb0Cpg1J1S=s64",
      "userId": "16141489273393480079"
     }
    },
    "outputId": "df4fbdb5-8efd-427e-b614-7d89eab562f7"
   },
   "source": [
    "# load text data (articles)\n",
    "df = pd.read_json('https://raw.githubusercontent.com/LambdaSchool/DS-Unit-4-Sprint-3-Deep-Learning/main/module1-rnn-and-lstm/wp_articles.json')\n",
    "df.head()"
   ],
   "execution_count": 22,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Contributing columnist\\n\\nThe House is on fire...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>When President Trump announced his decision to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Russian President Vladimir Putin speaks at a s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>“The Queen’s Speech” is designed to acknowledg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>Like an aging rock star, the president is now ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               article\n",
       "0    Contributing columnist\\n\\nThe House is on fire...\n",
       "1    When President Trump announced his decision to...\n",
       "10   Russian President Vladimir Putin speaks at a s...\n",
       "100  “The Queen’s Speech” is designed to acknowledg...\n",
       "101  Like an aging rock star, the president is now ..."
      ]
     },
     "metadata": {
      "tags": []
     },
     "execution_count": 22
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "54b3f47f5eeed6cf3fd9732ac8abf1e5",
     "grade": false,
     "grade_id": "cell-292d1e2b08c74976",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "M46Iu7jPvsVJ",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1622303876451,
     "user_tz": 300,
     "elapsed": 2940,
     "user": {
      "displayName": "Brian Hu",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gg9C2hp-ML87Vme0BJw6zcKYZK-PtGb0Cpg1J1S=s64",
      "userId": "16141489273393480079"
     }
    },
    "outputId": "af75fb8c-a803-4f1f-c794-24e6d4ce0621"
   },
   "source": [
    "# YOUR CODE HERE\n",
    "# raise NotImplementedError()\n",
    "\n",
    "# Create the sequence data\n",
    "text = \" \".join(df['article'])\n",
    "maxlen = 40\n",
    "step = 5\n",
    "\n",
    "\n",
    "# Unique Characters\n",
    "chars = list(set(text))\n",
    "\n",
    "# Lookup Tables\n",
    "char_int = {c:i for i, c in enumerate(chars)} \n",
    "int_char = {i:c for i, c in enumerate(chars)} \n",
    "\n",
    "encoded = [char_int[c] for c in text]\n",
    "\n",
    "sequences = [] # Each element is 40 chars long\n",
    "next_char = [] # One element for each sequence\n",
    "\n",
    "for i in range(0, len(encoded) - maxlen, step):\n",
    "    \n",
    "    sequences.append(encoded[i : i + maxlen])\n",
    "    next_char.append(encoded[i + maxlen])\n",
    "    \n",
    "print('sequences: ', len(sequences))\n",
    "\n",
    "\n",
    "# Create x & y\n",
    "\n",
    "x = np.zeros((len(sequences), maxlen, len(chars)), dtype=np.bool)\n",
    "y = np.zeros((len(sequences),len(chars)), dtype=np.bool)\n",
    "\n",
    "for i, sequence in enumerate(sequences):\n",
    "    for t, char in enumerate(sequence):\n",
    "        x[i,t,char] = 1\n",
    "    y[i, next_char[i]] = 1\n",
    "        \n"
   ],
   "execution_count": 26,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "sequences:  178374\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b46715962d32c041b4849afdf6c87232",
     "grade": false,
     "grade_id": "cell-6a39513d81d87f1b",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "id": "AnBNwzJgvsVK",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1622303881540,
     "user_tz": 300,
     "elapsed": 273,
     "user": {
      "displayName": "Brian Hu",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gg9C2hp-ML87Vme0BJw6zcKYZK-PtGb0Cpg1J1S=s64",
      "userId": "16141489273393480079"
     }
    }
   },
   "source": [
    "# YOUR CODE HERE\n",
    "# raise NotImplementedError()\n",
    "model = Sequential()\n",
    "model.add(LSTM(128, input_shape=(maxlen, len(chars))))\n",
    "model.add(Dense(len(chars), activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam')"
   ],
   "execution_count": 27,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "7cjYAi2rvsVK",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1622303882889,
     "user_tz": 300,
     "elapsed": 8,
     "user": {
      "displayName": "Brian Hu",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gg9C2hp-ML87Vme0BJw6zcKYZK-PtGb0Cpg1J1S=s64",
      "userId": "16141489273393480079"
     }
    }
   },
   "source": [
    "def sample(preds, temperature=1.0):\n",
    "    \"\"\"\n",
    "    Helper function to sample an index from a probability array\n",
    "    \"\"\"\n",
    "    # convert preds to array \n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "    # scale values \n",
    "    preds = np.log(preds) / temperature\n",
    "    # exponentiate values\n",
    "    exp_preds = np.exp(preds)\n",
    "    # this equation should look familar to you (hint: it's an activation function)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "    # Draw samples from a multinomial distribution\n",
    "    probas = np.random.multinomial(1, preds, 1)\n",
    "    # return the index that corresponds to the max probability \n",
    "    return np.argmax(probas)\n",
    "\n",
    "def on_epoch_end(epoch, _):\n",
    "    \"\"\"\"\n",
    "    Function invoked at end of each epoch. Prints the text generated by our model.\n",
    "    \"\"\"\n",
    "    \n",
    "    print()\n",
    "    print('----- Generating text after Epoch: %d' % epoch)\n",
    "    \n",
    "\n",
    "    start_index = random.randint(0, len(text) - dctk.maxlen - 1)\n",
    "    \n",
    "    generated = ''\n",
    "    \n",
    "    sentence = text[start_index: start_index + dctk.maxlen]\n",
    "    generated += sentence\n",
    "    \n",
    "    print('----- Generating with seed: \"' + sentence + '\"')\n",
    "    sys.stdout.write(generated)\n",
    "    \n",
    "    for i in range(400):\n",
    "        \n",
    "        x_dims = (1, dctk.maxlen, dctk.n_features)\n",
    "        x_pred = np.zeros(x_dims)\n",
    "        \n",
    "        for t, char in enumerate(sentence):\n",
    "            x_pred[0, t, dctk.char_int[char]] = 1\n",
    "            \n",
    "        preds = model.predict(x_pred, verbose=0)[0]\n",
    "        next_index = sample(preds)\n",
    "        next_char = dctk.int_char[next_index]\n",
    "        \n",
    "        sentence = sentence[1:] + next_char\n",
    "        \n",
    "        sys.stdout.write(next_char)\n",
    "        sys.stdout.flush()\n",
    "    print()"
   ],
   "execution_count": 28,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "uf4WI02S2_hq",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1622304099356,
     "user_tz": 300,
     "elapsed": 117,
     "user": {
      "displayName": "Brian Hu",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gg9C2hp-ML87Vme0BJw6zcKYZK-PtGb0Cpg1J1S=s64",
      "userId": "16141489273393480079"
     }
    }
   },
   "source": [
    "def on_epoch_end(epoch, _):\n",
    "    # Function invoked at end of each epoch. Prints generated text.\n",
    "    \n",
    "    print()\n",
    "    print('----- Generating text after Epoch: %d' % epoch)\n",
    "    \n",
    "    start_index = random.randint(0, len(text) - maxlen - 1)\n",
    "    \n",
    "    generated = ''\n",
    "    \n",
    "    sentence = text[start_index: start_index + maxlen]\n",
    "    generated += sentence\n",
    "    \n",
    "    print('----- Generating with seed: \"' + sentence + '\"')\n",
    "    sys.stdout.write(generated)\n",
    "    \n",
    "    for i in range(400):\n",
    "        x_pred = np.zeros((1, maxlen, len(chars)))\n",
    "        for t, char in enumerate(sentence):\n",
    "            x_pred[0, t, char_int[char]] = 1\n",
    "            \n",
    "        preds = model.predict(x_pred, verbose=0)[0]\n",
    "        next_index = sample(preds)\n",
    "        next_char = int_char[next_index]\n",
    "        \n",
    "        sentence = sentence[1:] + next_char\n",
    "        \n",
    "        sys.stdout.write(next_char)\n",
    "        sys.stdout.flush()\n",
    "    print()\n",
    "\n",
    "\n",
    "print_callback = LambdaCallback(on_epoch_end=on_epoch_end)"
   ],
   "execution_count": 34,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "UQ3gWlMYvsVL",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1622304102788,
     "user_tz": 300,
     "elapsed": 109,
     "user": {
      "displayName": "Brian Hu",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gg9C2hp-ML87Vme0BJw6zcKYZK-PtGb0Cpg1J1S=s64",
      "userId": "16141489273393480079"
     }
    }
   },
   "source": [
    "# need this for on_epoch_end()\n",
    "# text = \" \".join(data)"
   ],
   "execution_count": 35,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "S0BFtoKUIM2x",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1622304103139,
     "user_tz": 300,
     "elapsed": 4,
     "user": {
      "displayName": "Brian Hu",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gg9C2hp-ML87Vme0BJw6zcKYZK-PtGb0Cpg1J1S=s64",
      "userId": "16141489273393480079"
     }
    }
   },
   "source": [
    "# create callback object that will print out text generation at the end of each epoch \n",
    "# use for real-time monitoring of model performance\n",
    "print_callback = LambdaCallback(on_epoch_end=on_epoch_end)"
   ],
   "execution_count": 36,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kIaxdvUyvsVM"
   },
   "source": [
    "---------\n",
    "### Build Text Generating Model"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "deletable": false,
    "id": "p7XeGd0a2MKi",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f6cb82e3e8cab149b063e8a7705aeae9",
     "grade": false,
     "grade_id": "cell-0b9d84be1c960668",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1622304531156,
     "user_tz": 300,
     "elapsed": 427591,
     "user": {
      "displayName": "Brian Hu",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gg9C2hp-ML87Vme0BJw6zcKYZK-PtGb0Cpg1J1S=s64",
      "userId": "16141489273393480079"
     }
    },
    "outputId": "3b71857f-27bd-44ce-c41c-4ac681ed5104"
   },
   "source": [
    "# YOUR CODE HERE\n",
    "# raise NotImplementedError()\n",
    "\n",
    "# fit the model\n",
    "model.fit(x, y,\n",
    "          batch_size=32,\n",
    "          epochs=10,\n",
    "          callbacks=[print_callback])"
   ],
   "execution_count": 37,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "5575/5575 [==============================] - 26s 5ms/step - loss: 2.1929\n",
      "\n",
      "----- Generating text after Epoch: 0\n",
      "----- Generating with seed: \"ther, Sergey, 47, is serving their favor\"\n",
      "ther, Sergey, 47, is serving their favor on ipsrillds the parghin of Pincsiia I, but in Mlreftes. Mn’y crals.\n",
      "\n",
      "The this micaniacs and suep. Cfielt late bather Asi#of ach suptoding..\n",
      "\n",
      "“Dasdontatae Kallisaisulichs,” Sthickers. The noutrlatiod, be noth you tepmentitios impoint titho echatringe burnesifl. im owment wo hare our edlofet Homvente pasitosl blact be the mercham hap erone wer tist many thet Trump a beainsl of a Myerearu: Phen, wa\n",
      "Epoch 2/10\n",
      "5575/5575 [==============================] - 26s 5ms/step - loss: 2.0539\n",
      "\n",
      "----- Generating text after Epoch: 1\n",
      "----- Generating with seed: \"ss domestic product, and none of the pro\"\n",
      "ss domestic product, and none of the produticuria ports of in a’shels pruster as a retonted an the atill to han aneshing they beys Frone it anweess. Sint with the Moxiach Jorion Hist hote the ovilu thep in Jatisn a cotlentg: what him, Jot, Daidon’ Deandicera wat! Eur Featam.\n",
      "\n",
      "Mort Jamie and sothing s methren thee i yours thicly ho hawe fyrne on the coments apectad: htost.\n",
      "\n",
      "3Tit’ tuldion ensubeem. Echiros in the tarled the howst the fieh\n",
      "Epoch 3/10\n",
      "5575/5575 [==============================] - 26s 5ms/step - loss: 1.9593\n",
      "\n",
      "----- Generating text after Epoch: 2\n",
      "----- Generating with seed: \"across the ring, kneeing Rose in the fac\"\n",
      "across the ring, kneeing Rose in the fach ald violy agveesing sweat, (\n",
      "Awchofsion, by the leet to theoughs could. He the fust whem liznss frial corsing as applate newment Unine,” go, the parsen to corretione. We herd wime ut the pocrinition a dewplusioneone-, with anmone mitre, a lowe masers and Iria Boins has somed tolis, suatelt and persicuess and spacts woin betherab6y vingt to deve Marl Trumpall cas of a dreascressation lid eveots b\n",
      "Epoch 4/10\n",
      "5575/5575 [==============================] - 27s 5ms/step - loss: 1.8878\n",
      "\n",
      "----- Generating text after Epoch: 3\n",
      "----- Generating with seed: \"eights, along with the nearby Shaw and U\"\n",
      "eights, along with the nearby Shaw and Ukraaine, Buts Ilact, 14 OFV. teperner bat Oace aspents in a tups to pristion of fish Inatted on shil not reversence phecticarled 1:. Steel will the long.\n",
      "\n",
      "A round Nunizane. Kurncy, the nates ol Isllonan. Josts. Furngrs with suscesestions, eage kinned f5ir deforment’s somatire on and requibe and the surfonging muating: But the gnee lair houghting, yerely Jan Fricia reffatlowal on sightment and Onle\n",
      "Epoch 5/10\n",
      "5575/5575 [==============================] - 26s 5ms/step - loss: 1.8303\n",
      "\n",
      "----- Generating text after Epoch: 4\n",
      "----- Generating with seed: \"ug pricing legislation — and said he thi\"\n",
      "ug pricing legislation — and said he thisd which where minted odguay Schiff to the fiding sefter this spacesffemment, Mt. GasU as the ound suppoul shaker a trome sill will the mo immuty bark, we it trime the Terkished national Chrokmals a curregts and Jack Wr-Zelecarisk, fot ald butsels, agares olloniz Cali-Ming body dool. You pirrt contritn that sustering the busdired skilly insole of we will we say with, in whree it 18.\n",
      "\n",
      ": You ass in \n",
      "Epoch 6/10\n",
      "5575/5575 [==============================] - 27s 5ms/step - loss: 1.7821\n",
      "\n",
      "----- Generating text after Epoch: 5\n",
      "----- Generating with seed: \"ot only after attention and sympathy, bu\"\n",
      "ot only after attention and sympathy, bun for enity for they trueshally milly, force oorto componmented eld inflitr,” ky on olvercomaly sign, Inding.” stapling aveatures. “Ipation goin sox event lawy pardyeres his publuction, would morespern that him Unicap of oul and as will groab up to fleisanter unding mome theover have before trom.\n",
      "\n",
      "64 hos gill this.\n",
      "\n",
      "“Soped to Trump spenser,” said your Sacklask Javinatia were hoist to to the terr, \n",
      "Epoch 7/10\n",
      "5575/5575 [==============================] - 26s 5ms/step - loss: 1.7396\n",
      "\n",
      "----- Generating text after Epoch: 6\n",
      "----- Generating with seed: \"sed on the exploits of Philippe Petit, a\"\n",
      "sed on the exploits of Philippe Petit, act alqued to the has methoring rightrions.’s throighown’s ficsol.\n",
      "\n",
      "““Mut forthors, arengen to a Busten lating her shill with reppreide.\n",
      "\n",
      "Ropbeale-Vire of the chilh after has a gettert out his a. Cuthen’s home spoks of clandy, are his dewiture aling the to fooders is thas a finizersares, he casised now burchise he hain comede livel of 13-2 Coldry If Trump apmesabiely lyen indenn of the the works, a\n",
      "Epoch 8/10\n",
      "5575/5575 [==============================] - 27s 5ms/step - loss: 1.7028\n",
      "\n",
      "----- Generating text after Epoch: 7\n",
      "----- Generating with seed: \"he showrunners received a cease-and-desi\"\n",
      "he showrunners received a cease-and-desing to Antimist ollisa flersiflent for untary.\n",
      "\n",
      "The’re bricks, the include herse instated at was too dign moing mome. You relust decicues and billes, wed behomered took and that the was out thes menation formaled to and other critication.”\n",
      "\n",
      "“Ir a planed of ornowitians to orney in the K&C shere to a bake be worker to wand of you in president.’ I wan a crisin Condayer The forch from chancite dase to \n",
      "Epoch 9/10\n",
      "5575/5575 [==============================] - 27s 5ms/step - loss: 1.6717\n",
      "\n",
      "----- Generating text after Epoch: 8\n",
      "----- Generating with seed: \"to us over the Internet.\n",
      "\n",
      "Other Importan\"\n",
      "to us over the Internet.\n",
      "\n",
      "Other Importanglay mecrivens only cleve much beer didgn to the days retors officiars or fure ol aremed before Vorig Services are cleim. What sammations at Outo Jom Fack “Asterners has offinianc. Shis you had ach schediess and from “econd.\n",
      "\n",
      "As J. SECeorouch Veastor. Four you and poses a during Trump is state” his reserate.”\n",
      "\n",
      "\n",
      "\n",
      "— wo act. In over yauge and anyshime an the Desplined that tax to me thinks at support\n",
      "Epoch 10/10\n",
      "5575/5575 [==============================] - 27s 5ms/step - loss: 1.6420\n",
      "\n",
      "----- Generating text after Epoch: 9\n",
      "----- Generating with seed: \"ather of his daughter] has a longstandin\"\n",
      "ather of his daughter] has a longstanding a revive relaws in 1003, 28 froot: EP-Can of Priver Willing to thind than lanked to releast, a devent on screendings briestration severy thrage expecteing is uptions by News Natume to tald a race-it was she opposting the rost meated a during a daim. “They trueself in cosn to Frortably time bucken, wrein, I colloted avout of beco smating whes breeting expline early wreskn.\n",
      "\n",
      "AD\n",
      "\n",
      "Carola Helvier the\n"
     ],
     "name": "stdout"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f18d63ea110>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "execution_count": 37
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jBt5ugHKIM21"
   },
   "source": [
    "-------------\n",
    "## Challenge\n",
    "\n",
    "You will be expected to use a Keras LSTM to generate text on today's assignment. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ger33u0CIM22"
   },
   "source": [
    "# Review\n",
    "\n",
    "- <a href=\"#p1\">Part 1: </a>Describe Neural Networks used for modeling sequences\n",
    "    * Sequence Problems:\n",
    "        - Time Series (like Stock Prices, Weather, etc.)\n",
    "        - Text Classification\n",
    "        - Text Generation\n",
    "        - And many more! :D\n",
    "    * LSTMs are generally preferred over RNNs for most problems\n",
    "    * LSTMs are typically a single hidden layer of LSTM type; although, other architectures are possible.\n",
    "    * Keras has LSTMs/RNN layer types implemented nicely\n",
    "- <a href=\"#p2\">Part 2: </a>Apply a LSTM to a text generation problem using Keras\n",
    "    * Shape of input data is very important\n",
    "    * Can take a while to train\n",
    "    * You can use it to write movie scripts. :P "
   ]
  }
 ]
}